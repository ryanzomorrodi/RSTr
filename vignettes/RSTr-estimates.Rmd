---
title: "04: Generating Estimates: Age-standardization, Reliability, and Suppression"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{04: Generating Estimates: Age-standardization, Reliability, and Suppression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Overview

In the previous vignette, we discussed the model setup process in-depth. But how do we get our estimates once we've run our model? In this vignette, we discuss extracting estimates from our model object with the `get_estimates()` function, age-standardization with `age-standardize()`, and how we can use reliability criteria to suppress our estimates with `suppress_estimates()`.

## The `get_medians()` function

```{r, include = FALSE}
library(RSTr)
mstcar(name = "my_test_model", data = miheart, adjacency = miadj)
run_sampler("my_test_model")
```

In `RSTr-samples`, we generated age-standardized estimates for `lambda` based on our example Michigan dataset. To get the medians, we simply put our samples into `get_medians()`:

```{r}
std_pop <- c(113154, 100640, 95799)
margin_age <- 2
samples <- load_samples("my_test_model") * 1e5
samples <- age_standardize(samples, std_pop, margin_age, groups = 1:3, bind_new = TRUE, new_name = "35-64")
medians <- get_medians(samples)
```

From here, we can map our estimates:

```{r}
library(ggplot2)

est_35_64 <- medians[, "35-64", "1979"]

ggplot(mishp) +
  geom_sf(aes(fill = est_35_64)) +
  labs(
    title = "Smoothed Myocardial Infarction Death Rates in MI, Ages 35-64, 1979",
    fill = "Deaths per 100,000"
  ) +
  scale_fill_viridis_c() +
  theme_void()
```

Recall, though, in the previous vignette, we discovered that some traceplots were not as stable (i.e., reliable) as others. How can we test for reliability in our estimates?

## Estimate reliability

Reliability can be easily tested in CAR models using two criteria:

-   Relative precision: In [Quick, et al 2024](https://doi.org/10.1177/0282423X241244917), relative precision is measured as a ratio of the posterior median to its credible interval. If an estimate's ratio is less than 1, then that estimate is considered unreliable at that level of credibility. Effectively, this means that unreliable estimates have a spread of samples larger than the value of the estimate itself; and
-   Population counts: Though `RSTr` is designed to stabilize low-population regions, there is a limit to the amount of information the model can gather, and estimates from exceedingly low-population regions may be over-smoothed. Therefore, estimates from any region that fall below a specified threshold will be considered unreliable, regardless of relative precision. Use your judgment when setting this threshold depending on what kind of data you are working with: for example, 1,000 population is generally a good rule of thumb for mortality data, whereas an appropriate cutoff for birth data is closer to 100. Note that this population count metric only applies for unrestricted models; the enhancements of the restricted CAR models mean that we don't need this criterion when evaluating reliability.

Let's get some reliability metrics for our dataset. First, let's generate our relative precisions at 95% credibility using the `get_credible_interval()` and `get_relative_precision()` functions, then create a `logical` `array` that tells us which estimates are unreliable:

```{r}
ci <- get_credible_interval(sample = samples, perc_ci = 0.95)
rel_prec <- get_relative_precision(medians, ci)
low_rel_prec <- rel_prec < 1
```

Now, let's generate a similar `logical` `array` for populations less than 1000 and use these criteria to create a set of suppressed medians. A median will be suppressed if it meets either of the two criteria. Note that since our samples are age-standardized, we also have to extend our `pop` array to match in size using the `aggregate_count()` function:

```{r}
pop <- load_pop("my_test_model")
pop <- aggregate_count(pop, margin_age, groups = 1:3, bind_new = TRUE, new_name = "35-64")
low_population <- pop < 1000
medians_supp <- medians
medians_supp[low_rel_prec | low_population] <- NA
```

Looking at our dataset, we can see that most of our estimates meet both criteria! Certain counties, unfortunately, are too small to get reliable estimates for, but fortunately our estimates generally had high relative precision. Let's now map our suppressed estimates again and see what changed:

```{r}
est_35_64 <- medians_supp[, "35-64", "1979"]

ggplot(mishp) +
  geom_sf(aes(fill = est_35_64)) +
  labs(
    title = "Smoothed Myocardial Infarction Death Rates in MI, Ages 35-64, 1979",
    fill = "Deaths per 100,000"
  ) +
  scale_fill_viridis_c() +
  theme_void()
```

In this group in 1979, it seems only one region has been suppressed (i.e., grayed out). This is because age-standardizing the samples after running the model both helps to bolster our relative precisions and to increase the total population in our groups, increasing values for both suppression criteria. If we suppress our estimates in our more granular, non-age-standardized `samples` samples, we will see that, even with a small credible interval, many more counties are suppressed:

```{r}
rel_prec50 <- get_relative_precision(medians, ci = get_credible_interval(samples, 0.5))
low_rel_prec <- rel_prec50 < 1
medians_supp <- medians
medians_supp[low_rel_prec | low_population] <- NA
est_35_44 <- medians_supp[, "35-44", "1979"]

ggplot(mishp) +
  geom_sf(aes(fill = est_35_44)) +
  labs(
    title = "Smoothed Myocardial Infarction Death Rates in MI, Ages 35-44, 1979",
    subtitle = "Relative Precision based on 50% Credible Interval",
    fill = "Deaths per 100,000"
  ) +
  scale_fill_viridis_c() +
  theme_void()
```

As we widen our credible interval, the reliability criteria will become more conservative and suppress more counties:

```{r}
rel_prec995 <- get_relative_precision(medians, get_credible_interval(samples, 0.995))
low_rel_prec <- rel_prec995 < 1
medians_supp <- medians
medians_supp[low_rel_prec | low_population] <- NA
est_35_44 <- medians_supp[, "35-44", "1979"]

ggplot(mishp) +
  geom_sf(aes(fill = est_35_44)) +
  labs(
    title = "Smoothed Myocardial Infarction Death Rates in MI, Ages 35-44, 1979",
    subtitle = "Relative Precision based on 99.5% Credible Interval",
    fill = "Deaths per 100,000"
  ) +
  scale_fill_viridis_c() +
  theme_void()
```

As we increase our CI width from 0.50 to 0.95 to 0.99 and 0.995, our estimates must be more precise and more counties become grayed out. It is important to find a good balance between credible interval choice and displaying of estimates. Usually, a 95% credible interval provides a happy medium and is the value that is traditionally used.

## Final thoughts

In this vignette, we explored the `get_medians()` function, investigated measures of reliability, and observed how reliability measures changed which data are suppressed. This vignette concludes the main sections on using the functions in the `RSTr` package. After reading these, you should be able to prepare your event and adjacency data, configure your model as necessary, and determine which estimates are reliable. If you are interested in learning more about how the MSTCAR model itself works, read `vignette("RSTr-models")`.